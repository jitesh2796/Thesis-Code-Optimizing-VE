{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VE Implementation Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 0: Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import os \n",
    "from time import time \n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from openai import OpenAI\n",
    "import certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override bad SSL_CERT_FILE if set\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing VE libraries\n",
    "from utils import *\n",
    "from dataset_utils import read_wikiqa_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 1: Few Shot answer generations\n",
    "\n",
    "(Using Code from few_shot.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_context_prediction(ex, shots, engine, style=\"standard\", length_test_only=False, n=1):\n",
    "\n",
    "    if style == \"standard\":\n",
    "        showcase_examples = [\n",
    "            \"Q: {}\\nA: {}\\n\".format(s[\"question\"], s[\"answer\"]) for s in shots\n",
    "        ]\n",
    "        input_example = \"Q: {}\\nA:\".format(ex[\"question\"])\n",
    "        prompt = \"\\n\".join(showcase_examples + [input_example])\n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported prompt style\")\n",
    "\n",
    "    temp = 0.7 if n > 1 else 0.0\n",
    "\n",
    "    try:\n",
    "        resp = openai.Completion.create(\n",
    "            engine=engine, prompt=prompt, max_tokens=32, stop='\\n',\n",
    "            temperature=temp, logprobs=5, echo=True, n=n\n",
    "        )\n",
    "\n",
    "        pred = resp if n > 1 \n",
    "    except Exception as e:\n",
    "        print(f'Encountered Error {e}')\n",
    "\n",
    "    if n > 1:\n",
    "        return pred\n",
    "    else:\n",
    "        return resp[\"choices\"][0]\n",
    "\n",
    "    # pred[\"id\"] = ex[\"id\"]\n",
    "    # pred[\"prompt\"] = prompt\n",
    "    # try:\n",
    "    #     if len(pred[\"text\"]) > len(prompt):\n",
    "    #         pred[\"text\"] = pred[\"text\"][len(prompt):]\n",
    "    #     else:\n",
    "    #         pred[\"text\"] = \"null\"\n",
    "    #     return pred\n",
    "    # except:\n",
    "    #     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original Function, will dissect it into multiple \n",
    "\n",
    "def test_few_shot_performance(args):\n",
    "    print(\"Running prediction\")\n",
    "    train_set = read_wikiqa_data(f\"data/train_subset.json\")\n",
    "    train_set = train_set[args.train_slice:(args.train_slice + args.num_shot)]\n",
    "    dev_set = read_wikiqa_data(f\"data/dev_sampled.json\")\n",
    "    dev_set = dev_set[args.dev_slice:(args.num_dev)]\n",
    "\n",
    "    showcase_examples = [\n",
    "        \"Q: {}\\nA: {}\\n\".format(s[\"question\"], s[\"answer\"]) for s in train_set\n",
    "    ]\n",
    "    prompt = \"\\n\".join(showcase_examples)\n",
    "    print('prompt: ')\n",
    "    print(prompt)\n",
    "    \n",
    "    if os.path.exists(result_cache_name(args)) and not args.run_length_test:\n",
    "        predictions = read_json(result_cache_name(args))\n",
    "    else:\n",
    "        predictions = []\n",
    "        for x in tqdm(dev_set, total=len(dev_set), desc=\"Predicting\"):\n",
    "            pred = in_context_prediction(x, train_set, engine=args.engine, \\\n",
    "                style=args.style, length_test_only=args.run_length_test)\n",
    "            if pred == None:\n",
    "                args.num_dev = len(predictions)\n",
    "                break\n",
    "            else:\n",
    "                predictions.append(pred)\n",
    "\n",
    "        if args.run_length_test:\n",
    "            print(result_cache_name(args))\n",
    "            print('MAX', max(predictions), 'COMP', 32)\n",
    "            return\n",
    "        # save\n",
    "        dump_json(predictions, result_cache_name(args))\n",
    "    # acc\n",
    "    for p in predictions:\n",
    "        p['answer_prob'] = calc_fewshot_pred_with_prob(p, args.style) \n",
    "    evaluate_few_shot_predictions(dev_set, predictions, do_print=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-sampling 500 records from the VE test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_json(\"data/dev_sampled.json\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>entity_ids</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>evidences</th>\n",
       "      <th>answer</th>\n",
       "      <th>evidences_id</th>\n",
       "      <th>answer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>604cd3220bdd11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the award that the director of film Pu...</td>\n",
       "      <td>[[Etan Boritzer, [Etan Boritzer( born 1950) is...</td>\n",
       "      <td>Q7258905_Q3291382</td>\n",
       "      <td>[[Pugachev (1978 film), 0], [Alexey Saltykov (...</td>\n",
       "      <td>[[Pugachev, director, Aleksei Saltykov], [Alek...</td>\n",
       "      <td>People's Artist of the RSFSR</td>\n",
       "      <td>[[Q7258905, director, Q3291382], [Q3291382, aw...</td>\n",
       "      <td>Q47024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>6108c3a7097e11ebbdb0ac1f6bf848b6</td>\n",
       "      <td>comparison</td>\n",
       "      <td>Are both Les Tortillards and Trivial (Film) fr...</td>\n",
       "      <td>[[One and Five, [One and Five is a 1969 short ...</td>\n",
       "      <td>Q3235772_Q2987804</td>\n",
       "      <td>[[Les Tortillards, 0], [Trivial (film), 0]]</td>\n",
       "      <td>[[Les Tortillards, country of origin, French],...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[[Q3235772, country of origin, Q142], [Q298780...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>c5d56fe60bd911eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the date of death of Lancelot Lowther,...</td>\n",
       "      <td>[[Humphrey de Bohun, 7th Earl of Hereford, [Hu...</td>\n",
       "      <td>Q6483626_Q5725106</td>\n",
       "      <td>[[Lancelot Lowther, 6th Earl of Lonsdale, 0], ...</td>\n",
       "      <td>[[Lancelot Edward Lowther, 6th Earl of Lonsdal...</td>\n",
       "      <td>15 August 1876</td>\n",
       "      <td>[[Q6483626, father, Q5725106], [Q5725106, date...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>eb63d1060bae11ebab90acde48001122</td>\n",
       "      <td>inference</td>\n",
       "      <td>Who is the father-in-law of Marcus Vinicius (C...</td>\n",
       "      <td>[[Marcus Vinicius (consul 30), [Marcus Viniciu...</td>\n",
       "      <td>Q1247301_Q237629</td>\n",
       "      <td>[[Marcus Vinicius (consul 30), 0], [Julia Livi...</td>\n",
       "      <td>[[Marcus Vinicius, spouse, Julia Livilla], [Ju...</td>\n",
       "      <td>Germanicus</td>\n",
       "      <td>[[Q1247301, spouse, Q237629], [Q237629, father...</td>\n",
       "      <td>Q191039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>728d56420bdd11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the place of birth of the director of ...</td>\n",
       "      <td>[[Jesse E. Hobson, [Jesse Edward Hobson( May 2...</td>\n",
       "      <td>Q7737654_Q28998</td>\n",
       "      <td>[[The Great Awakening (film), 0], [Reinhold Sc...</td>\n",
       "      <td>[[The Great Awakening, director, Reinhold Schü...</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>[[Q7737654, director, Q28998], [Q28998, place ...</td>\n",
       "      <td>Q1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  _id           type  \\\n",
       "284  604cd3220bdd11eba7f7acde48001122  compositional   \n",
       "785  6108c3a7097e11ebbdb0ac1f6bf848b6     comparison   \n",
       "292  c5d56fe60bd911eba7f7acde48001122  compositional   \n",
       "746  eb63d1060bae11ebab90acde48001122      inference   \n",
       "624  728d56420bdd11eba7f7acde48001122  compositional   \n",
       "\n",
       "                                              question  \\\n",
       "284  What is the award that the director of film Pu...   \n",
       "785  Are both Les Tortillards and Trivial (Film) fr...   \n",
       "292  What is the date of death of Lancelot Lowther,...   \n",
       "746  Who is the father-in-law of Marcus Vinicius (C...   \n",
       "624  What is the place of birth of the director of ...   \n",
       "\n",
       "                                               context         entity_ids  \\\n",
       "284  [[Etan Boritzer, [Etan Boritzer( born 1950) is...  Q7258905_Q3291382   \n",
       "785  [[One and Five, [One and Five is a 1969 short ...  Q3235772_Q2987804   \n",
       "292  [[Humphrey de Bohun, 7th Earl of Hereford, [Hu...  Q6483626_Q5725106   \n",
       "746  [[Marcus Vinicius (consul 30), [Marcus Viniciu...   Q1247301_Q237629   \n",
       "624  [[Jesse E. Hobson, [Jesse Edward Hobson( May 2...    Q7737654_Q28998   \n",
       "\n",
       "                                      supporting_facts  \\\n",
       "284  [[Pugachev (1978 film), 0], [Alexey Saltykov (...   \n",
       "785        [[Les Tortillards, 0], [Trivial (film), 0]]   \n",
       "292  [[Lancelot Lowther, 6th Earl of Lonsdale, 0], ...   \n",
       "746  [[Marcus Vinicius (consul 30), 0], [Julia Livi...   \n",
       "624  [[The Great Awakening (film), 0], [Reinhold Sc...   \n",
       "\n",
       "                                             evidences  \\\n",
       "284  [[Pugachev, director, Aleksei Saltykov], [Alek...   \n",
       "785  [[Les Tortillards, country of origin, French],...   \n",
       "292  [[Lancelot Edward Lowther, 6th Earl of Lonsdal...   \n",
       "746  [[Marcus Vinicius, spouse, Julia Livilla], [Ju...   \n",
       "624  [[The Great Awakening, director, Reinhold Schü...   \n",
       "\n",
       "                           answer  \\\n",
       "284  People's Artist of the RSFSR   \n",
       "785                           yes   \n",
       "292                15 August 1876   \n",
       "746                    Germanicus   \n",
       "624                       Hamburg   \n",
       "\n",
       "                                          evidences_id answer_id  \n",
       "284  [[Q7258905, director, Q3291382], [Q3291382, aw...    Q47024  \n",
       "785  [[Q3235772, country of origin, Q142], [Q298780...      None  \n",
       "292  [[Q6483626, father, Q5725106], [Q5725106, date...      None  \n",
       "746  [[Q1247301, spouse, Q237629], [Q237629, father...   Q191039  \n",
       "624  [[Q7737654, director, Q28998], [Q28998, place ...     Q1055  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "compositional        446\n",
       "bridge_comparison    226\n",
       "comparison           218\n",
       "inference            110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(500)\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_json(\"data/dev_sampled_500.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Few shot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' From VE code'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' From VE code'''\n",
    "\n",
    "# def _parse_args():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     add_engine_argumenet(parser)\n",
    "#     # standard, instruction, etc\n",
    "#     parser.add_argument('--style', type=str, default=\"standard\")\n",
    "#     parser.add_argument('--annotation', type=str, default=\"std\")\n",
    "#     parser.add_argument('--run_prediction', default=False, action='store_true')\n",
    "#     parser.add_argument('--run_length_test', default=False, action='store_true')\n",
    "#     parser.add_argument('--num_shot', type=int, default=6)\n",
    "#     parser.add_argument('--train_slice', type=int, default=0)\n",
    "#     parser.add_argument('--num_dev', type=int, default=1000) # firs 58 for calibrating, last 250 for testing\n",
    "#     parser.add_argument('--dev_slice', type=int, default=0)\n",
    "#     parser.add_argument('--show_result',  default=False, action='store_true')\n",
    "#     parser.add_argument('--model', type=str, default=\"gpt3\")\n",
    "#     parser.add_argument('--show_prompt',  default=False, action='store_true')\n",
    "#     args = parser.parse_args()    \n",
    "#     specify_engine(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(style='standard', annotation='std', run_prediction=False, run_length_test=False, num_shot=5, train_slice=0, num_dev=500, dev_slice=0, show_result=False, model='gpt3.5', show_prompt=False, engine='gpt-3.5-turbo-0125')\n"
     ]
    }
   ],
   "source": [
    "# Defining args parameter\n",
    "args = argparse.Namespace(\n",
    "    style=\"standard\",\n",
    "    annotation=\"std\",\n",
    "    run_prediction=False,\n",
    "    run_length_test=False,\n",
    "    num_shot=5,\n",
    "    train_slice=0,\n",
    "    num_dev=500,\n",
    "    dev_slice=0,\n",
    "    show_result=False,\n",
    "    model=\"gpt3.5\",\n",
    "    show_prompt=False,\n",
    "    engine = \"gpt-3.5-turbo-0125\"\n",
    ")\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 not found\n"
     ]
    }
   ],
   "source": [
    "train_set = read_wikiqa_data(f\"data/train_subset.json\", manual_annotation_style= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 not found\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set[args.train_slice:(args.train_slice + args.num_shot)]\n",
    "dev_set = read_wikiqa_data(f\"data/dev_sampled.json\")\n",
    "dev_set = dev_set[args.dev_slice:(args.num_dev)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      "Q: Which film was released earlier, Kistimaat or I'M Taraneh, 15?\n",
      "A: I'M Taraneh, 15\n",
      "\n",
      "Q: What is the date of death of the composer of film Baalaraajana Kathe?\n",
      "A: 27 May 1980\n",
      "\n",
      "Q: Who is the spouse of the director of film Alive (1993 Film)?\n",
      "A: Kathleen Kennedy\n",
      "\n",
      "Q: Who lived longer, Edward Frederick Sanderson or Forrest Towns?\n",
      "A: Edward Frederick Sanderson\n",
      "\n",
      "Q: Which country the director of film Battle Circus (Film) is from?\n",
      "A: American\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showcase_examples = [\n",
    "    \"Q: {}\\nA: {}\\n\".format(s[\"question\"], s[\"answer\"]) for s in train_set\n",
    "]\n",
    "prompt = \"\\n\".join(showcase_examples)\n",
    "print('prompt: ')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dev_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_context_prediction(ex, shots, engine, style=\"standard\", length_test_only=False, n=1):\n",
    "\n",
    "    if style == \"standard\":\n",
    "        showcase_examples = [\n",
    "            \"Q: {}\\nA: {}\\n\".format(s[\"question\"], s[\"answer\"]) for s in shots\n",
    "        ]\n",
    "        input_example = \"Q: {}\\nA:\".format(ex[\"question\"])\n",
    "        prompt = \"\\n\".join(showcase_examples + [input_example])\n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported prompt style\")\n",
    "    \n",
    "    temp = 0.7 if n > 1 else 0.0\n",
    "\n",
    "    try:\n",
    "        resp = openai.Completion.create(\n",
    "            engine=engine, prompt=prompt, max_tokens=32, stop='\\n',\n",
    "            temperature=temp, logprobs=5, echo=True, n=n\n",
    "        )\n",
    "\n",
    "        pred = resp if n > 1 \n",
    "    except Exception as e:\n",
    "        print(f'Encountered Error {e}')\n",
    "\n",
    "    if n > 1:\n",
    "        return pred\n",
    "    else:\n",
    "        return resp[\"choices\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Which film was released earlier, Kistimaat or I'M Taraneh, 15?\n",
      "A: I'M Taraneh, 15\n",
      "\n",
      "Q: What is the date of death of the composer of film Baalaraajana Kathe?\n",
      "A: 27 May 1980\n",
      "\n",
      "Q: Who is the spouse of the director of film Alive (1993 Film)?\n",
      "A: Kathleen Kennedy\n",
      "\n",
      "Q: Who lived longer, Edward Frederick Sanderson or Forrest Towns?\n",
      "A: Edward Frederick Sanderson\n",
      "\n",
      "Q: Which country the director of film Battle Circus (Film) is from?\n",
      "A: American\n",
      "\n",
      "Q: Where was the performer of song Get A Life – Get Alive born?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "in_context_prediction(x, train_set, engine=args.engine, \\\n",
    "                style=args.style, length_test_only=args.run_length_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered Error \n",
      "\n",
      "You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'pred' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43min_context_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_test_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_length_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[72], line 26\u001b[0m, in \u001b[0;36min_context_prediction\u001b[0;34m(ex, shots, engine, style, length_test_only, n)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n\u001b[0;32m---> 26\u001b[0m \u001b[43mpred\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ex[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     27\u001b[0m pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m prompt\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'pred' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "pred = in_context_prediction(x, train_set, engine=args.engine,\n",
    "    style=args.style, length_test_only=args.run_length_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under a starry sky, a gentle unicorn danced through a shimmering forest, leaving trails of moonlight that whispered sweet dreams to all who slept.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where was the performer of song Get A Life – Get Alive born?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = x['question']\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Which film was released earlier, Kistimaat or I'M Taraneh, 15?\n",
      "A: I'M Taraneh, 15\n",
      "\n",
      "Q: What is the date of death of the composer of film Baalaraajana Kathe?\n",
      "A: 27 May 1980\n",
      "\n",
      "Q: Who is the spouse of the director of film Alive (1993 Film)?\n",
      "A: Kathleen Kennedy\n",
      "\n",
      "Q: Who lived longer, Edward Frederick Sanderson or Forrest Towns?\n",
      "A: Edward Frederick Sanderson\n",
      "\n",
      "Q: Which country the director of film Battle Circus (Film) is from?\n",
      "A: American\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instructions = prompt\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=args.engine,\n",
    "    input= input,\n",
    "    instructions= prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The performer of the song \"Get A Life - Get Alive\" is Peter John Cox, and he was born in Kingston upon Thames, England.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_681331e0cedc8191af805b63e4021d0a0b08a7d788721748', created_at=1746088416.0, error=None, incomplete_details=None, instructions='Only return the answer and not complete sentence.', metadata={}, model='gpt-3.5-turbo-0125', object='response', output=[ResponseOutputMessage(id='msg_681331e163e88191a25f3410650f5d510b08a7d788721748', content=[ResponseOutputText(annotations=[], text='Kingston, Jamaica', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=165, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=5, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=170), user=None, store=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example = \"Q: {}\\nA:\".format(x[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\\n\".join([prompt] + [input_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Which film was released earlier, Kistimaat or I'M Taraneh, 15?\n",
      "A: I'M Taraneh, 15\n",
      "\n",
      "Q: What is the date of death of the composer of film Baalaraajana Kathe?\n",
      "A: 27 May 1980\n",
      "\n",
      "Q: Who is the spouse of the director of film Alive (1993 Film)?\n",
      "A: Kathleen Kennedy\n",
      "\n",
      "Q: Who lived longer, Edward Frederick Sanderson or Forrest Towns?\n",
      "A: Edward Frederick Sanderson\n",
      "\n",
      "Q: Which country the director of film Battle Circus (Film) is from?\n",
      "A: American\n",
      "\n",
      "Q: Where was the performer of song Get A Life – Get Alive born?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=args.engine,\n",
    "    input= input,\n",
    "    instructions= \"Only return the answer and not complete sentence.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kingston, Jamaica'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": input}],\n",
    "    n=5,\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a joke.\"\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature= 0.7,\n",
    "    n=3\n",
    ")\n",
    "\n",
    "pred = {}\n",
    "responses =[]\n",
    "# 'completion.choices' will contain a list of 5 responses\n",
    "for choice in completion.choices:\n",
    "    responses.append(choice.message.content)\n",
    "\n",
    "pred[\"responses\"] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'responses': [\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired!\",\n",
       "  'Why did the scarecrow win an award? Because he was outstanding in his field!',\n",
       "  \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BSJr11MIVubI5D0pPIdTw5UhCRqvN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='Why did the scarecrow win an award? Because he was outstanding in his field!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=3, logprobs=None, message=ChatCompletionMessage(content='Why did the scarecrow win an award?\\nBecause he was outstanding in his field!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=4, logprobs=None, message=ChatCompletionMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1746089203, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=78, prompt_tokens=12, total_tokens=90, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle find its way home? Because it lost its bearings!\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletion' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletion' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "completion[\"id\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
