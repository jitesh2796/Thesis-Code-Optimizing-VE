{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 0: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os \n",
    "from time import time \n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from openai import OpenAI\n",
    "import certifi\n",
    "\n",
    "# Override bad SSL_CERT_FILE if set\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing VE libraries\n",
    "from utils import *\n",
    "from dataset_utils import read_wikiqa_data\n",
    "from prompt_helper import get_joint_prompt_helper, normalize_prediction\n",
    "from dataset_utils import read_wikiqa_data, wiki_evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_self_ask import self_ask_prompt\n",
    "from consistency import _parse_args as consistency_parse_args, in_context_manual_prediction  as consistency_in_context_manual_prediction, post_process_consistency, evaluate_manual_predictions as consistency_evaluate_manual_predictions\n",
    "from verifying_questions import extract_follow_up_questions, _parse_args as verifying_questions_args\n",
    "from relevant_context import _parse_args as relevant_context_args\n",
    "\n",
    "\n",
    "from verifying_answers import in_context_manual_prediction as verifying_answers_in_context_manual_prediction, _parse_args as verifying_answers_args\n",
    "from answer_again import in_context_manual_prediction as answer_again_in_context_manual_prediction\n",
    "from evaluation import evaluate_model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 1: Building Consolidated function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model embedding function required for relevant context\n",
    "def model_embeddings(sentence, model):\n",
    "    embedding = model.encode([sentence])\n",
    "    return embedding[0] #should return an array of shape 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iterative_prediction():\n",
    "\n",
    "    # Consistency Arguments\n",
    "    args = consistency_parse_args()\n",
    "\n",
    "    output_file = f\"misc/iterative_predictions_self_ask_final_iter_new_0_250.jsonl\"\n",
    "\n",
    "    # Load existing IDs from output file\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line.strip())\n",
    "                    existing_ids.add(data[\"id\"])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    # train_set = read_wikiqa_data(\"data/train_subset.json\", manual_annotation_style=args.style)\n",
    "    # train_set = train_set[args.train_slice:(args.train_slice + args.num_shot)]\n",
    "\n",
    "    dev_set = read_wikiqa_data(\"data/dev_sampled.json\")\n",
    "    dev_set = dev_set[args.dev_slice:(args.dev_slice + args.num_dev)]\n",
    "\n",
    "    results = []\n",
    "    total_start = time()\n",
    "\n",
    "    for idx, ex in enumerate(tqdm(dev_set, desc=\"Processing one-by-one\")):\n",
    "        if ex['id'] in existing_ids:\n",
    "            continue\n",
    "\n",
    "        start = time()\n",
    "        try:\n",
    "            # Step 1: Predict\n",
    "            raw_pred = consistency_in_context_manual_prediction(ex, self_ask_prompt, engine=args.engine, prompt_helper=args.helper, length_test_only=False, n=args.num_shot)\n",
    "            \n",
    "            # Step 2: Consistency post-processing\n",
    "            con_score, final_pred = post_process_consistency(ex, raw_pred, args)\n",
    "            final_pred[\"consistency\"]= con_score\n",
    "\n",
    "            # Step  3: check if the consistency is higher than the threshold\n",
    "            # args =verifying_questions_args()\n",
    "\n",
    "            if con_score > 0.5:\n",
    "                # Step 4: Storing the result if consistency is higher than the threshold \n",
    "                final_pred['high_consistency'] = True\n",
    "                final_pred[\"time_taken_sec\"] = round(time() - start, 2)\n",
    "                with open(output_file, \"a\") as fout:\n",
    "                    fout.write(json.dumps(final_pred) + \"\\n\")\n",
    "\n",
    "            else:\n",
    "                start2 = time()\n",
    "                final_pred[\"consistency_time\"] = round(start2 - start, 2)\n",
    "                final_pred['high_consistency'] = False\n",
    "                # Step 5: Generating verifying questions\n",
    "\n",
    "                sentences = rationale_tokenize(final_pred['rationale'])\n",
    "                # extracting follow up questions directly from the self-ask prompt, no need of LLM call\n",
    "                vq = extract_follow_up_questions(final_pred['rationale'])\n",
    "                \n",
    "                final_pred[\"verifying_questions\"] = vq\n",
    "\n",
    "                # Step 5: Pulling Relevant Context\n",
    "                start3 = time()\n",
    "                final_pred[\"time_verifying_question\"] = round(start3 - start2, 2)\n",
    "                args = relevant_context_args()\n",
    "\n",
    "                contexts = []\n",
    "                embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2').to(device)\n",
    "\n",
    "                # sentences = rationale_tokenize(final_pred['rationale'])\n",
    "                all_pars_text = []\n",
    "                all_pars = []\n",
    "                va = []\n",
    "                for j, s in enumerate(sentences):\n",
    "                    pars_text = get_texts_to_rationale_wikipedia(vq[j], False)\n",
    "                \n",
    "                    pars_text = list(dict.fromkeys(pars_text)) #remove potential duplicates\n",
    "                    all_pars_text += pars_text\n",
    "\n",
    "                    if pars_text != []:\n",
    "                            # sen_embeds = [model_embeddings(s, embedding_model)]\n",
    "                            # Checking embedding from question instead of the answer\n",
    "                            sen_embeds = [model_embeddings(vq[j], embedding_model)]\n",
    "                            par_embeds = [model_embeddings(s, embedding_model) for s in pars_text]\n",
    "\n",
    "                            pars = sklearn.metrics.pairwise.pairwise_distances(sen_embeds, par_embeds)\n",
    "                            pars = pars.argsort(axis = 1)[0][:args.topk]\n",
    "\n",
    "                            pars = [pars_text[i] for i in pars]\n",
    "                            contexts.append(pars)\n",
    "                            all_pars += pars\n",
    "                    \n",
    "                    # Step 6: Creating Verified Answers\n",
    "                    answer = verifying_answers_in_context_manual_prediction(args.engine, args.helper, args.model, pars, vq[j])\n",
    "                    va.append(answer['text'].lstrip())\n",
    "                \n",
    "                start4 = time()\n",
    "                final_pred[\"time_context_and_verifying_answer\"] = round(start4- start3,2)\n",
    "                final_pred[\"context\"] = contexts\n",
    "                final_pred[\"verifying_answers\"] = va\n",
    "\n",
    "                # Step 7: Answering Again\n",
    "                new_rationale = answer_again_rationale(vq, va)\n",
    "\n",
    "                final_pred[\"new_rationale\"] = new_rationale\n",
    "                new_p = answer_again_in_context_manual_prediction(ex, self_ask_prompt, args.engine, args.helper, args.model,\n",
    "                    new_rationale )\n",
    "\n",
    "                start5 =time()\n",
    "                final_pred[\"time_answer_again\"] = round(start5 - start4, 2)\n",
    "                final_pred[\"new_answer\"] = new_p[\"text\"]\n",
    "                \n",
    "                final_pred[\"time_taken_sec\"] = round(time() - start, 2)\n",
    "                with open(output_file, \"a\") as fout:\n",
    "                    fout.write(json.dumps(final_pred) + \"\\n\")\n",
    "            \n",
    "            results.append(final_pred)\n",
    "\n",
    "            # # Step 4: Save this prediction to file immediately\n",
    "            # with open(output_file, \"a\") as fout:\n",
    "            #     fout.write(json.dumps(final_pred) + \"\\n\")\n",
    "\n",
    "        except Exception as e: \n",
    "            print(f\"Error in record {idx} ({ex['id']}): {e}\")\n",
    "            continue\n",
    "\n",
    "    total_duration = round(time() - total_start, 2)\n",
    "    avg_time = total_duration / len(results) if results else 0\n",
    "    print(f\"\\nâœ… Finished {len(results)} records in {total_duration:.2f} seconds (avg {avg_time:.2f} sec/record)\")\n",
    "    print(f\"ðŸ“„ Results saved to: {output_file}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing one-by-one:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 114/250 [08:48<1:09:27, 30.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in record 113 (1faf51ba0baf11ebab90acde48001122): HTTPSConnectionPool(host='en.wikipedia.org', port=443): Read timed out. (read timeout=10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing one-by-one:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 131/250 [12:18<1:03:13, 31.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in record 130 (3451827a088d11ebbd70ac1f6bf848b6): ('Connection aborted.', OSError(65, 'No route to host'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing one-by-one:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 134/250 [12:48<37:33, 19.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in record 133 (026b56060bde11eba7f7acde48001122): HTTPSConnectionPool(host='en.wikipedia.org', port=443): Read timed out. (read timeout=10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing one-by-one: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [28:11<00:00,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Finished 198 records in 1691.23 seconds (avg 8.54 sec/record)\n",
      "ðŸ“„ Results saved to: misc/iterative_predictions_self_ask_final_iter_new_0_250.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_iterative_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"misc/iterative_predictions_self_ask_final_iter_new_0_250.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, results =evaluate_model_performance(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match_percentage': 29.96,\n",
       " 'verify_percentage': 29.55,\n",
       " 'average_time_per_record_sec': 7.75}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>consistency</th>\n",
       "      <th>rationale</th>\n",
       "      <th>answer</th>\n",
       "      <th>right_answer</th>\n",
       "      <th>original_answers</th>\n",
       "      <th>original_rationales</th>\n",
       "      <th>consistency_time</th>\n",
       "      <th>high_consistency</th>\n",
       "      <th>verifying_questions</th>\n",
       "      <th>time_verifying_question</th>\n",
       "      <th>time_context_and_verifying_answer</th>\n",
       "      <th>context</th>\n",
       "      <th>verifying_answers</th>\n",
       "      <th>new_rationale</th>\n",
       "      <th>time_answer_again</th>\n",
       "      <th>new_answer</th>\n",
       "      <th>time_taken_sec</th>\n",
       "      <th>match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>1ee47f380bde11eba7f7acde48001122</td>\n",
       "      <td>Where was the performer of song Get A Life â€“ G...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>London</td>\n",
       "      <td>VÃ¶cklabruck</td>\n",
       "      <td>[American, London, England, London, Russia]</td>\n",
       "      <td>[Are follow up questions needed here: Yes.\\nFo...</td>\n",
       "      <td>2.76</td>\n",
       "      <td>False</td>\n",
       "      <td>[Who performed the song \"Get A Life - Get Aliv...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.21</td>\n",
       "      <td>[[Get a life or Get a Life may refer to:\\n\\nGe...</td>\n",
       "      <td>[Eric Papilaya performed the song \"Get A Life ...</td>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Austria.</td>\n",
       "      <td>22.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>49eb87280bdc11eba7f7acde48001122</td>\n",
       "      <td>Where did the director of film Don Juan (1922 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>Westerland</td>\n",
       "      <td>[Hollywood, Hollywood, Hollywood, Hollywood, H...</td>\n",
       "      <td>[Are follow up questions needed here: Yes.\\nFo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>2e17069c0bde11eba7f7acde48001122</td>\n",
       "      <td>What is the place of birth of the composer of ...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>[Indian, India, Indian, India, Indian]</td>\n",
       "      <td>[Are follow up questions needed here: Yes.\\nFo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>28942dc20bdd11eba7f7acde48001122</td>\n",
       "      <td>Where did the director of film Temptation (195...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Nice</td>\n",
       "      <td>[Los Angeles, Los Angeles, California, Los Ang...</td>\n",
       "      <td>[Are follow up questions needed here: Yes.\\nFo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>6a8a71280bb011ebab90acde48001122</td>\n",
       "      <td>Who is the uncle of John Kennedy, 2Nd Lord Ken...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>Gilbert Kennedy</td>\n",
       "      <td>James Kennedy</td>\n",
       "      <td>[Gilbert Kennedy, John Kennedy, John Kennedy o...</td>\n",
       "      <td>[Are follow up questions needed here: Yes.\\nFo...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>False</td>\n",
       "      <td>[Who is the parent of John Kennedy, 2nd Lord K...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>[[A member of the Kennedy family, he is a son ...</td>\n",
       "      <td>[The parent of John Kennedy, 2nd Lord Kennedy ...</td>\n",
       "      <td>Are follow up questions needed here: Yes.\\nFol...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>John F. Kennedy.</td>\n",
       "      <td>41.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  Are follow up questions needed here: Yes.\\nFol...   \n",
       "1  Are follow up questions needed here: Yes.\\nFol...   \n",
       "2  Are follow up questions needed here: Yes.\\nFol...   \n",
       "3  Are follow up questions needed here: Yes.\\nFol...   \n",
       "4  Are follow up questions needed here: Yes.\\nFol...   \n",
       "\n",
       "                                 id  \\\n",
       "0  1ee47f380bde11eba7f7acde48001122   \n",
       "1  49eb87280bdc11eba7f7acde48001122   \n",
       "2  2e17069c0bde11eba7f7acde48001122   \n",
       "3  28942dc20bdd11eba7f7acde48001122   \n",
       "4  6a8a71280bb011ebab90acde48001122   \n",
       "\n",
       "                                            question  consistency  \\\n",
       "0  Where was the performer of song Get A Life â€“ G...          0.4   \n",
       "1  Where did the director of film Don Juan (1922 ...          1.0   \n",
       "2  What is the place of birth of the composer of ...          0.6   \n",
       "3  Where did the director of film Temptation (195...          0.8   \n",
       "4  Who is the uncle of John Kennedy, 2Nd Lord Ken...          0.2   \n",
       "\n",
       "                                           rationale           answer  \\\n",
       "0  Are follow up questions needed here: Yes.\\nFol...           London   \n",
       "1  Are follow up questions needed here: Yes.\\nFol...        Hollywood   \n",
       "2  Are follow up questions needed here: Yes.\\nFol...           Indian   \n",
       "3  Are follow up questions needed here: Yes.\\nFol...      Los Angeles   \n",
       "4  Are follow up questions needed here: Yes.\\nFol...  Gilbert Kennedy   \n",
       "\n",
       "    right_answer                                   original_answers  \\\n",
       "0    VÃ¶cklabruck        [American, London, England, London, Russia]   \n",
       "1     Westerland  [Hollywood, Hollywood, Hollywood, Hollywood, H...   \n",
       "2          Tamil             [Indian, India, Indian, India, Indian]   \n",
       "3           Nice  [Los Angeles, Los Angeles, California, Los Ang...   \n",
       "4  James Kennedy  [Gilbert Kennedy, John Kennedy, John Kennedy o...   \n",
       "\n",
       "                                 original_rationales  consistency_time  \\\n",
       "0  [Are follow up questions needed here: Yes.\\nFo...              2.76   \n",
       "1  [Are follow up questions needed here: Yes.\\nFo...               NaN   \n",
       "2  [Are follow up questions needed here: Yes.\\nFo...               NaN   \n",
       "3  [Are follow up questions needed here: Yes.\\nFo...               NaN   \n",
       "4  [Are follow up questions needed here: Yes.\\nFo...              2.64   \n",
       "\n",
       "   high_consistency                                verifying_questions  \\\n",
       "0             False  [Who performed the song \"Get A Life - Get Aliv...   \n",
       "1              True                                                NaN   \n",
       "2              True                                                NaN   \n",
       "3              True                                                NaN   \n",
       "4             False  [Who is the parent of John Kennedy, 2nd Lord K...   \n",
       "\n",
       "   time_verifying_question  time_context_and_verifying_answer  \\\n",
       "0                      0.0                              19.21   \n",
       "1                      NaN                                NaN   \n",
       "2                      NaN                                NaN   \n",
       "3                      NaN                                NaN   \n",
       "4                      0.0                              37.67   \n",
       "\n",
       "                                             context  \\\n",
       "0  [[Get a life or Get a Life may refer to:\\n\\nGe...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  [[A member of the Kennedy family, he is a son ...   \n",
       "\n",
       "                                   verifying_answers  \\\n",
       "0  [Eric Papilaya performed the song \"Get A Life ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  [The parent of John Kennedy, 2nd Lord Kennedy ...   \n",
       "\n",
       "                                       new_rationale  time_answer_again  \\\n",
       "0  Are follow up questions needed here: Yes.\\nFol...               0.58   \n",
       "1                                                NaN                NaN   \n",
       "2                                                NaN                NaN   \n",
       "3                                                NaN                NaN   \n",
       "4  Are follow up questions needed here: Yes.\\nFol...               0.77   \n",
       "\n",
       "         new_answer  time_taken_sec  match_flag  \n",
       "0          Austria.           22.56           0  \n",
       "1               NaN            2.04           0  \n",
       "2               NaN            2.95           0  \n",
       "3               NaN            4.41           0  \n",
       "4  John F. Kennedy.           41.08           0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"misc/ve_predictions_self_ask_iter_latest_0_250.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4228187919463087"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "63/149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ve self ask 0-100 match percentage\n",
    "47%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
